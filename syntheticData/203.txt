1. Semi-parametric Bayesian moment estimation using exponentially tilted empirical likelihood (ETEL) incorporates fully Bayesian methods to address model misspecification. The Bayesian ETEL posterior distribution satisfies the Bernstein-von Mises theorem, offering a unified approach to calculate marginal likelihoods and Bayesian factors for model comparison. This method allows for the discard of misspecified moments and computes the marginal likelihood using the Chib's extended Metropolis-Hastings sampler, ensuring selection consistency.

2. The selection of valid moment restrictions in misspecified models is facilitated by the Kullback-Leibler divergence, which guides the selection towards moments closer to the true data generating process. The use of the Chib-Jeliazkov selection criterion, based on the marginal likelihood, aids in choosing the model that best approximates the true process.

3. A comprehensive modeling framework for spatial survival data with arbitrary censoring uses a semi-parametric proportional hazards and proportional odds model, along with accelerated failure time models. This approach simultaneously accommodates uncensored, interval-censored, and current status data, handling spatial locations at the county level.

4. The stochastic block model (SBM) and its variants are powerful tools for analyzing community structure in networks. Efficient network cross-validation techniques, such as degree-corrected SBM, facilitate the determination of community assignments. Block-wise node pair splitting and integrated stepwise community recovery algorithms have been demonstrated to be robust across a wide range of community structures.

5. Modeling healthcare utilization patterns from massive medical claims data involves translating claims into a sequence of discrete events. Exponential and proportional hazards mixture models capture patient heterogeneity, enabling clustering of patients based on their utilization behaviors. This approach helps identify the main drivers of healthcare utilization, while controlling for demographic and geographic factors.

1. A semi-parametric Bayesian approach is applied to moment-based casting, where exponentially tilted empirical likelihood (ETEL) is integrated within a fully Bayesian framework. This method accurately addresses moment misspecification by allowing the posterior to satisfy Bernstein von Mises (BVM) theorem. The unified marginal likelihood Bayesian factor is utilized for comparing restricted models, discarding misspecified moments. The computation of the marginal likelihood utilizes the Chib-Jeliazkov method, ensuring selection consistency. The ETEL Bayesian approach selects the model that best fits the observed moments, as indicated by the Kullback-Leibler divergence, and offers a broader theoretical foundation for practical applications.

2. The confidence region estimation in spatial threshold modeling involves repeated noisy fine grid location data. An asymptotic Gaussian target is constructed, with dependent nested excursions forming the sub- and super-threshold true excursions. The desired confidence region is determined using a multiplier bootstrap, which does not require Gaussianity or stationarity assumptions. The original stationarity and smoothness conditions of the limiting Gaussian field are utilized to determine the confidence region, facilitating the analysis of temperature trends in North America for the mid-21st century.

3. A comprehensive unified model is proposed for arbitrarily censored spatial survival data, incorporating semi-parametric proportional hazards, proportional odds, and accelerated failure time models. Unlike previous methods, this approach simultaneously accommodates uncensored, interval-censored, and current status left- and right-censored data. The mixture of left-truncated data is also handled, along with time-dependent georeferenced locations and areal geographic units like counties. Formal model selection and assessment are facilitated using conditional Cox-Snell residuals and the log-pseudo marginal likelihood (LPML) for model comparison.

4. A stochastic block model (SBM) variant is introduced as an efficient tool for analyzing network community structure. Network cross-validation (NCV) is employed to determine the number of communities and the choice of regular or degree-corrected block models (DCBM). The block-wise node pair splitting technique is integrated with a stepwise community recovery algorithm, demonstrating solid performance across a wide range of community structures. This methodology has been extensively tested and proven effective for network community detection.

5. Modeling and characterizing heterogeneity in healthcare utilization involves translating massive medical claims data into individual-level discrete event sequences. An exponential proportional hazards mixture model is used to capture the heterogeneous behavior of patients. The objective is to cluster patients based on their longitudinal utilization patterns, identifying the main drivers of healthcare utilization while controlling for demographic, geographic, and health characteristics. This approach addresses the computational infeasibility of fitting high-dimensional parametric proportional hazards models by employing an iterative clustering procedure.

1. In the realm of Bayesian semiparametric moment estimation, the Exponentially Tilted Empirical Likelihood (ETEL) method has emerged as a robust approach that can accommodate misspecification in the moments. The Bernstein von Mises theorem ensures that the posterior distribution aligns with the true generating process, facilitating moment selection and the computation of the marginal likelihood. The Chib's extended Metropolis-Hastings sampler is instrumental in this context, offering a consistent framework for moment selection and enabling a direct comparison of misspecified models through the Bayesian factor. This approach is particularly useful when dealing with spatial threshold excursions in North America's seasonal temperature variations, where a comprehensive modeling strategy is essential.

2. The development of a unified framework for analyzing spatial survival data with arbitrary censoring mechanisms is a significant advancement in statistical methods. This approach integrates semiparametric proportional hazard, proportional odds, and accelerated failure time models, accommodating both censored and uncensored survival times. By employing a log-pseudo marginal likelihood and deviance information criterion, model fitting becomes straightforward, especially when handling georeferenced locations and spatial units. This methodology finds wide application in healthcare, particularly in modeling the utilization patterns of pediatric asthma patients within the Medicaid system.

3. The joint modeling of longitudinal data with an informative terminal event, such as patient mortality, is addressed through a semiparametric regression approach that accounts for right censoring. This method provides a direct interpretation of the terminal event's impact on the longitudinal response, ensuring that the relationship between the two remains intact. By maximizing the likelihood, it becomes possible to analyze medical costs for patients with end-stage renal disease, offering insights into cost management and healthcare policy.

4. The application of Zellner's mixture prior in generalized linear models (GLM) has been a subject of growing interest due to its robustness and flexibility. This approach extends the Bayesian selection criteria by incorporating a truncated compound confluent hypergeometric prior, which encompasses various special mixture priors. The local geometric properties of the prior and the asymptotic selection consistency are key factors in justifying the choice of prior. This methodology is implemented in the 'ba' package and finds extensive application in healthcare research, particularly in assessing the correlates of preterm delivery in HIV-infected mothers in Botswana.

5. Addressing the challenge of nonmonotone missing data in research, a Bayesian inverse probability weighting (IPW) approach has been proposed to circumvent the limitations of traditional IPW, which is largely restricted to monotone missingness mechanisms. By incorporating an incomplete augmented equation within the Bayesian framework, this method guarantees restrictions on the missing data process and enhances the efficiency of the IPW estimator. This innovative approach has been applied to evaluate the risk factors associated with preterm delivery and holds promise for advancing missing data analysis in various fields.

1. In the field of Bayesian semiparametric moment estimation, the Exponentially Tilted Empirical Likelihood (ETEL) approach has gained attention for its ability to handle misspecification correctly. This method utilizes the Bernstein-von Mises theorem to ensure that the posterior distribution satisfies the conditions for a valid Bayesian analysis. The ETEL framework allows for a unified treatment of marginal likelihood computation and model comparison, facilitating the selection of the most appropriate moment conditions. By restricting the moments to valid specifications, the ETEL method selects models that better reflect the true data generating process, as indicated by the Kullback-Leibler divergence.

2. Advances in spatial survival modeling have led to the development of a comprehensive and unified approach that accommodates arbitrarily censored data. This semiparametric proportional hazards model, which also includes proportional odds and accelerated failure time models, simultaneously accounts for uncensored, interval-censored, and current status left-censored survival times. The methodology, implemented in the SPBayesSurv package, has been shown to have broad applications, particularly in healthcare, where it significantly outperforms standard proportional hazards models.

3. Stochastic block models (SBM) are a variant of network community analysis tools that utilize efficient network cross-validation (NCV) to determine the optimal community structure. The degree-corrected block model (DCBM) integrates NCV with a node-pair splitting technique, leading to a more accurate community recovery. This algorithm has been extensively tested and demonstrated its effectiveness across a wide range of community detection tasks.

4. Analyzing healthcare utilization patterns from large medical claims databases presents a significant challenge due to the computational infeasibility of fitting high-dimensional parametric proportional hazards models. An iterative clustering approach that imputes cluster membership and draws upon longitudinal utilization behaviors can overcome this obstacle. This methodology has been applied to study the persistence of asthma in children enrolled in Medicaid across six states, leading to policy implications for targeted interventions to improve adherence to recommended care.

5. A joint modeling approach for analyzing longitudinal data with an informative terminal event and subject-level right censoring has been developed. This method accounts for the terminal event's impact on the longitudinal response through inverse probability weighting. The explicit modeling of the terminal event's effect offers an easily interpretable contrast to treating it as a simple conditional event in the longitudinal model. This approach has been applied to the analysis of medical costs for end-stage renal disease patients, providing insights into cost dynamics and treatment outcomes.

1. Semi-parametric Bayesian moment estimation with exponentially tilted empirical likelihood (ETEL) enables accurate estimation even when moments are misspecified. The Bayesian ETEL approach uses the Bernstein von Mises theorem to provide a unified marginal likelihood, facilitating model comparison and selection of valid moment restrictions, while appropriately discarding misspecified ones. The computation of the marginal likelihood is facilitated by the Chib-Jeliazkov approach and extended Metropolis-Hastings sampling, ensuring consistency in model selection.

2. Spatial survival modeling with semi-parametric proportional hazards and proportional odds models for accelerated failure time allows for the accommodation of arbitrarily censored spatial survival data. This approach, implemented in the SPBayesSurv package, outperforms standard models in fitting and predicting survival times, especially in high dimensions. The methodology is broadly applicable in healthcare research, particularly in analyzing patient care utilization sequences.

3. The stochastic block model (SBM) and its variants are powerful tools for analyzing network community structures. Efficient network cross-validation and community detection are achieved through degree-corrected block models and node-pair splitting techniques. These methods have been extensively demonstrated to be effective in community recovery across various networks, including social and biological systems.

4. Modeling healthcare utilization heterogeneity through massive medical claims data involves translating claims into individual-level discrete event sequences. Exponential and proportional hazard mixtures are employed to capture heterogeneous patient behaviors, with clustering based on longitudinal utilization patterns. This approach helps identify the main drivers of healthcare utilization variation, adjusting for demographic, geographic, and health characteristics of patients.

5. Analyzing the joint effect of latent frailty and terminal events in the presence of right censoring is facilitated by a semi-parametric likelihood regression approach. This method explicitly models the terminal event response, offering easy interpretation and comparison with conditional longitudinal models. It maintains the usual relationship between longitudinally measured responses and the terminal event stage, providing a straightforward interpretation of the association.

1. Bayesian semiparametric moment estimation using exponentially tilted empirical likelihood (ETEL) allows for fully Bayesian handling of misspecified moments. The posterior distribution of the ETEL satisfies the Bernstein-von Mises theorem, enabling the unified computation of the marginal likelihood and Bayesian model comparison. The method selects valid moment restrictions while discarding misspecified ones, facilitating the computation of the marginal likelihood through the extended Metropolis-Hastings algorithm and Chib's method. The selection consistency of the marginal likelihood is favored, resulting in the selection of models that are closer to the true data-generating process, as measured by the Kullback-Leibler divergence. This approach has broadened the theoretical underpinning of Bayesian ETEL and has shown promise in practical applications.

2. A comprehensive modeling framework is introduced for arbitrarily censored spatial survival data, employing semiparametric proportional hazards, proportional odds, and accelerated failure time models. Unlike previous methods, this approach simultaneously accommodates uncensored, interval censored, and current status left-censored data. The handling of right-censored survival times is also addressed. The methodology is implemented in the efficient and compiled package SPBayesSurv, which has demonstrated broad applications in proportional odds and accelerated failure time modeling, often outperforming proportional hazards models.

3. A variant of the stochastic block model (SBM), the degree-corrected block model (DCBM), is presented as a tool for analyzing network community structure. The network cross-validation (NCV) technique is used to determine the optimal community structure, choosing between regular SBM and DCBM. A block-wise node pair splitting technique is combined with an integrated step for community recovery, and the selection probability of vanishing nodes increases mildly with community size. This algorithm has been extensively demonstrated to recover community structures robustly across a wide range of conditions.

4. Modeling and characterizing heterogeneity in healthcare utilization from massive medical claims data involve translating medical claims into a sequence of discrete care utilization events. An exponential proportional hazards mixture model is employed to capture the heterogeneous behavior of patients. The objective is to cluster patients according to their longitudinal utilization patterns and to identify the main drivers of variation in healthcare utilization, while controlling for demographic, geographic, and health characteristics. This computational approach is particularly useful when fitting high-dimensional parametric proportional hazards models becomes infeasible.

5. The joint modeling of longitudinal outcomes and an informative terminal event with subject-specific random effects addresses the issue of right censoring. Analytical techniques include the use of inverse probability weighting and the explicit modeling of the effect of the terminal event on the longitudinal response. The proposed model offers a straightforward interpretation of the conditional longitudinal effects while maintaining the usual relationship between longitudinally measured responses and the time to the terminal event. The semiparametric likelihood regression approach is numerically maximized to analyze medical costs for patients with end-stage renal disease, providing desirable asymptotic properties.

1. Bayesian semiparametric moment estimation in tilted empirical likelihood (ETEL) enables accurate handling of misspecification in Bayesian models. The Bernstein-von Mises theorem guarantees the convergence of posterior distributions in the presence of misspecification, while the Bayesian ETET framework incorporates marginal likelihood computation for model comparison. Misspecification in moment restrictions can lead to invalid inferences, which are addressed through a robust approach that incorporates the misspecified moments, reducing the likelihood of Type I errors. The use of Chib's extended Metropolis-Hastings sampler facilitates computation of the marginal likelihood, enhancing the selection consistency of the Bayesian ETET. Additionally, the Kullback-Leibler divergence is employed to select the model that minimizes the distance to the true generating process, ensuring a closer fit.

2. In the context of spatial survival analysis, a unified semiparametric proportional hazards and proportional odds model is proposed. This model accommodates arbitrarily censored data, effectively handling spatial survival data with proportional hazards, proportional odds, and accelerated failure time components. Unlike traditional methods, this approach can simultaneously analyze censored survival times and uncensored interval-censored data, addressing the limitations of current statistical techniques. The methodology, implemented in the SPBayesSurv package, is applied to real-world data, demonstrating its superior performance in modeling healthcare utilization and its potential for broader application in survival analysis research.

3. Stochastic block models (SBM) and their variants are essential tools for the analysis of community structures in networks. An efficient network cross-validation technique, based on node pair splitting, is introduced to determine the optimal number of communities. This approach, known as stochastic block model with degree correction (DCBM), incorporates the degree distribution of the network nodes, resulting in more accurate community detection. The proposed method has been extensively tested on simulated and real-world networks, showcasing its robustness and reliability. The DCBM technique is particularly useful for the recovery of network communities in sparse graphs with power-law degree distributions, providing valuable insights into the underlying structure of complex systems.

4. The modeling of healthcare utilization patterns in patients with persistent asthma is explored through a Bayesian nonparametric mixture model. This approach clusters patients based on their longitudinal utilization behavior, aiding in the identification of the main drivers of healthcare utilization. The methodology is applied to a large dataset of children enrolled in Medicaid, spanning six states, to examine the impact of adherence to recommended care on the frequency of asthma-related healthcare visits. The results have important policy implications for targeted interventions to improve pediatric asthma care, highlighting the role of demographic and geographic factors in healthcare utilization variability.

5. A Bayesian semiparametric approach to joint modeling of longitudinal data and terminal events is presented, addressing the challenges of informative terminal event censoring. The proposed method, based on inverse probability weighting, provides explicit measures of the terminal event's effect, offering straightforward interpretation of the results. The methodology is applied to the analysis of medical costs for patients with end-stage renal disease, demonstrating its effectiveness in capturing the complex relationships between longitudinal responses and terminal events. The model's desirable asymptotic properties and computational efficiency make it a valuable tool for medical cost analysis and other survival-related research questions.

1. The article discusses the application of Bayesian semiparametric moment casting in exponentially tilted empirical likelihood (ETEL) to handle correctly misspecified moments in Bayesian analysis. The use of ETEL posterior distributions helps to satisfy the Bernstein-von Mises theorem, which allows for a unified marginal likelihood and Bayes factor comparison. The article emphasizes the importance of correctly restricting moments to avoid misspecification and explores computational methods such as the Chib extended Metropolis-Hastings sampler for efficient computation of marginal likelihoods. It also highlights the Kullback-Leibler divergence as a measure to select moment restrictions that closely match the true data generating process.

2. The text delves into the use of Bayesian semiparametric proportional hazards and proportional odds models for analyzing spatial survival data. It discusses the accommodation of arbitrary censoring and the handling of spatial locations through nested random effects, with a focus on the efficiency gains from conditional likelihood estimation. The application of the methodology to modeling temperature changes in North America is highlighted, showcasing the expected temperature increase in the mid-21st century.

3. The article presents a stochastic block model variant for analyzing community structure in networks. It introduces an efficient network cross-validation method to determine the number of communities and the block-wise node pair splitting technique for community recovery. The use of degree-corrected block models and the integration of community detection with the stochastic block model are discussed, along with extensive simulations demonstrating the algorithm's robustness across various community structures.

4. The text explores the use of exponential and proportional hazards mixtures to model healthcare utilization sequences, capturing patient heterogeneity. It discusses the clustering of patients based on their longitudinal utilization patterns and the identification of key drivers of healthcare utilization, while controlling for demographic and health characteristics. The application of the methodology to children's healthcare utilization in the Medicaid system with a focus on asthma is presented, leading to policy implications for targeted interventions.

5. The article addresses the joint modeling of longitudinal outcomes and terminal events in the presence of informative right censoring. It introduces a Bayesian semiparametric approach to estimate the latent frailty effects and the marginal structural equation model with inverse probability weighting to account for the terminal event's influence. The methodology's application to analyzing medical costs for end-stage renal disease patients is discussed, emphasizing the favorable asymptotic properties of the model.

1. In an exploration of Bayesian semi-parametric moment estimation under exponentially tilted empirical likelihood (ETEL), a fully Bayesian approach is presented to handle the issue of moment misspecification. This method ensures that the posterior distribution adheres to the Bernstein-von Mises theorem, providing a unified framework for comparing moment restrictions and effectively dealing with misspecified moments. The computation of the marginal likelihood is facilitated by the Chib's extended Metropolis-Hastings sampler and the selection consistency of the marginal likelihood is examined.

2. The selection of valid moment restrictions is crucial when dealing with misspecified marginal likelihoods. By employing the Kullback-Leibler divergence, a strategy is proposed to select moment restrictions that closely align with the true data generating process. This approach enhances the theoretical underpinnings of Bayesian ETEL and its practical applications, offering insights into the construction of confidence regions for spatial threshold excursions in a noisy fine grid location setting.

3. The expected temperature increase in North America during the mid-21st century is modeled using a comprehensive unified approach that accommodates arbitrarily censored spatial survival data. This semiparametric proportional hazard and proportional odds model, along with the accelerated failure time framework, simultaneously handles censored survival times and uncensored interval censoring. The methodology is applied to analyze the baseline survival of patients with end-stage renal disease.

4. A stochastic block model (SBM) variant, incorporating efficient network cross-validation (NCV), is introduced as a tool for analyzing community structure in networks. The NCV technique aids in determining the optimal community structure, and the degree-corrected block model (DCBM) with NCV and block-wise node pair splitting further enhances community recovery. This methodology has been extensively validated and demonstrates robust performance across a wide range of community recovery algorithms.

5. Healthcare utilization heterogeneity is modeled and characterized using massive medical claims data, translating patient-level claims into a sequence of discrete care events. An exponential proportional hazard mixture model captures the heterogeneous behavior of patients, enabling the clustering of patients based on their longitudinal utilization patterns. This approach helps identify the primary drivers of healthcare utilization, while controlling for demographic, geographic, and health characteristics of the patients.

1. Bayesian Semiparametric Moment Casting for Exponentially Tilted Empirical Likelihood: A Fully Bayesian Approach to Correctly Misspecified Moments
   This paper introduces a Bayesian semiparametric moment casting framework within exponentially tilted empirical likelihood (ETEL) that addresses the issue of misspecification in moments. By utilizing the Bernstein-von Mises theorem, we establish the posterior convergence of our Bayesian ETEL to the true generating process. The paper presents a unified approach for comparing models using moment restrictions, with the flexibility to discard misspecified moments. We also discuss the computation of the marginal likelihood using the Chib's extended Metropolis-Hastings sampler and the consistency of marginal likelihood selection. Finally, we apply our methodology to a real-world dataset, illustrating the benefits of correctly specifying moments in Bayesian ETEL.

2. Model Selection with Marginal Likelihood in Bayesian ETEL: Exploring the Kullback-Leibler Divergence Perspective
   This study explores the idea of using the Kullback-Leibler divergence to broaden the theoretical underpinning of Bayesian semiparametric moment casting within exponentially tilted empirical likelihood (ETEL). We propose a new selection criterion based on the Kullback-Leibler divergence between the misspecified and true generating processes. This criterion allows us to select models that are closer to the true generating process, thereby reducing the Kullback-Leibler divergence. We demonstrate the effectiveness of our approach through a simulation study and apply it to a real-world dataset, showcasing its ability to select the correct model in the presence of misspecification.

3. Bayesian ETEL for Spatial Survival Analysis: A Unified Modeling Approach for Arbitrarily Censored Spatial Survival Data
   In this paper, we introduce a Bayesian semiparametric approach for modeling spatial survival data with arbitrarily censored observations. Our approach, which is based on exponentially tilted empirical likelihood (ETEL), accommodates different types of censoring, including right censoring, interval censoring, and current status left censoring. By using a proportional hazards model and a proportional odds model within the ETEL framework, we provide a comprehensive and flexible modeling framework for spatial survival data. We demonstrate the advantages of our approach through a simulation study and apply it to a real-world dataset, showing improved fit compared to traditional survival models.

4. Bayesian ETEL for Network Community Detection: A Stochastic Block Model Approach
   This study presents a Bayesian semiparametric approach for detecting communities in networks using the stochastic block model (SBM). By incorporating the ETEL framework, we provide a flexible and robust method for community detection that accounts for the inherent uncertainty in the network structure. We introduce a novel cross-validation technique to determine the number of communities and the adjacency matrix. We compare our Bayesian ETEL approach with other community detection algorithms and demonstrate its superior performance in detecting network communities. We also apply our methodology to a real-world network dataset, illustrating its practical utility.

5. Bayesian ETEL for Heterogeneous Healthcare Utilization: Modeling and Clustering Patient Utilization Sequences
   In this paper, we introduce a Bayesian semiparametric approach for modeling and clustering patient healthcare utilization sequences. By incorporating the ETEL framework, we provide a flexible and robust method for modeling heterogeneous healthcare utilization behavior. We propose a clustering algorithm to group patients based on their longitudinal utilization behavior and identify the main drivers of healthcare utilization. We demonstrate the advantages of our approach through a simulation study and apply it to a real-world dataset of medical claims, showcasing its ability to identify patient clusters and understand the drivers of healthcare utilization.

1. A comprehensive analysis of the semi-parametric Bayesian moment estimation within the framework of exponentially tilted empirical likelihood (ETEL) is presented. The study discusses the Bayesian approach to handling misspecification in moment estimation, ensuring the posterior distribution aligns with the Bernstein-von Mises theorem. The unified marginal likelihood and Bayesian factor are explored for model comparison, while the restricted model discards misspecified moments. The computation of the marginal likelihood is facilitated by the Chib's extended Metropolis-Hastings sampler and the consistency of the marginal likelihood in model selection is emphasized. The selection process aims to approximate the true generating process, guided by the Kullback-Leibler divergence to minimize the discrepancy between models.

2. An innovative approach to modeling spatially censored survival data is introduced, incorporating semiparametric proportional hazards and proportional odds models alongside accelerated failure time models. The methodology accommodates various types of censoring, including left-truncated and interval-censored data, allowing for the precise modeling of time-dependent georeferenced locations. The selection of the best model is facilitated through the use of log-pseudo marginal likelihood and deviance information criterion, ensuring the chosen model aligns with the observed survival patterns. The proposed approach is implemented in the efficient and compiled package 'spBayesSurv', offering a broad range of applications in survival analysis.

3. The stochastic block model (SBM) and its variants are powerful tools for analyzing community structures in networks. The study highlights the efficiency of network cross-validation (NCV) in determining the optimal community structure and the choice of the regular stochastic block model or the degree-corrected block model. The NCV technique, combined with the block-wise node pair splitting approach, ensures robust community recovery, even in the presence of vanishing nodes. The methodology has been extensively tested and demonstrated its effectiveness in a wide range of community detection algorithms.

4. Healthcare utilization is characterized by significant heterogeneity, which poses challenges for policymakers and healthcare providers. The research focuses on translating massive medical claims data into a sequence of discrete care utilization events. A mixture of exponential and proportional hazard models captures the heterogeneous behaviors of patients. The study aims to cluster patients based on their longitudinal utilization patterns, thereby identifying the main drivers of healthcare utilization while controlling for demographic, geographic, and health characteristics. The computational feasibility of fitting high-dimensional proportional hazard models is addressed through an iterative algorithm that imputes cluster membership and simulates care utilization behaviors.

5. The joint modeling of longitudinal outcomes and informative terminal events, subject to right censoring, is tackled through a Bayesian semiparametric approach. The study emphasizes the explicit modeling of the latent frailty and its effects on the terminal event response, offering an easily interpretable contrast to treating the terminal event time as a fixed cut-off. The conditional longitudinal modeling maintains the usual relationship between the longitudinally measured response and the time to the terminal event, ensuring straightforward interpretation and maintaining the integrity of the data structure. The methodology is applied to the analysis of medical costs in patients with end-stage renal disease, providing insights into the cost dynamics associated with terminal events.

1. Semi-parametric Bayesian moment estimation within the framework of exponentially tilted empirical likelihood (ETEL) is an approach that offers a fully Bayesian solution to the problem of misspecified moments. By utilizing the ETEL posterior, which satisfies the Bernstein von Mises (BVM) theorem, we can establish a unified framework for comparing moment restrictions while discarding misspecified ones. The computation of the marginal likelihood is facilitated by the Chib's extended Metropolis-Hastings sampler and the Jeliazkov selection consistency. The goal is to favor the minimum valid moment restrictions, as misspecified marginal likelihood selection can lead to the selection of models that are further from the true generating process. The Kullback-Leibler divergence provides a measure to broaden the theoretical underpinning of Bayesian ETEL, and its practical applications are discussed in the context of estimating temperature increases in North America.

2. A comprehensive unified modeling framework is proposed for arbitrarily censored spatial survival data, utilizing semi-parametric proportional hazard and proportional odds models, as well as accelerated failure time models. Unlike traditional methods that handle censored survival times separately, this approach accommodates both uncensored and interval-censored data simultaneously. The current status of left and right censoring, along with mixture and left-truncated models, is addressed. The handling of time-dependent georeferenced locations, exact areal locations of geographic units such as counties, and spatial locations is facilitated through formal selection methods. The assessment of model fit is carried out using conditional Cox-Snell residual plots and the choice of models is based on the log pseudo marginal likelihood (LPML) and deviance information criterion (DIC). The baseline survival is modeled using transformed Bernstein polynomials with a priori fitting, all implemented in an efficient compiled package called spBayesSurv.

3. A variant of the stochastic block model (SBM), known as the degree-corrected block model (DCBM), serves as a powerful tool for analyzing network community structure. The efficient network cross-validation (NCV) determines the community structure by choosing the regular SBM or the degree-corrected variant. The block-wise node pair splitting technique, combined with an integrated step for community recovery, utilizes the adjacency matrix probability selection. This method demonstrates solid performance and has been extensively tested for community recovery algorithms. It is particularly effective for a wide range of community sizes, with the selection probability vanishing as the community size increases.

4. Modeling and characterizing heterogeneity in healthcare utilization from massive medical claims data involve translating individual-level claims into a sequence of discrete care events. This sequence is captured using an exponential proportional hazard mixture model, which accounts for the heterogeneous behavior of patients in healthcare utilization. The objective is to cluster patients according to their longitudinal utilization behavior and to identify the main drivers of variation in healthcare utilization, while controlling for demographic, geographic, and health characteristics of the patients. This approach addresses the computational infeasibility of fitting parametric proportional hazard models in high dimensions and uses an iterative stepwise imputation to draw cluster membership and utilization behavior, as demonstrated in a study on pediatric asthma in the Medicaid system across six states.

5. Analyzing the longitudinal occurrence of informative terminal events with subject-specific right censoring is facilitated by a joint modeling approach that incorporates latent frailty and marginal equation estimation with inverse probability weighting. This method explicitly models the effect of the terminal event on the response variable, providing an easily interpretable contrast to treating the terminal event time as a simple censoring event. The conditional longitudinal model maintains a straightforward interpretation of the relationship between the longitudinally measured response and the time to the terminal event. The semiparametric likelihood regression approach, which handles right-censored terminal event times, is maximized numerically to analyze medical costs for patients with end-stage renal disease, offering desirable asymptotic properties.

1. Article: This article explores the use of Bayesian semiparametric moment casting within exponentially tilted empirical likelihood (ETEL) in fully Bayesian models to correctly account for misspecification. The posterior distribution satisfies the Bernstein-von Mises (BvM) theorem, providing a unified approach to computing marginal likelihood and Bayes factors for model comparison. The method allows for the discarding of misspecified moments while maintaining computational efficiency through the use of the Chib-Jeliazkov selection criterion and extended Metropolis-Hastings sampling. The goal is to select valid moment restrictions that closely align with the true data generating process, as measured by the Kullback-Leibler divergence.

2. Article: This paper presents a comprehensive unified modeling framework for arbitrarily censored spatial survival data using semiparametric proportional hazards, proportional odds, and accelerated failure time models. Unlike previous approaches, this methodology simultaneously accommodates uncensored, interval-censored, and current status left-censored data, as well as georeferenced and areally defined spatial locations. Formal model selection is facilitated by assessing the fit using conditional Cox-Snell residuals and log-pseudo marginal likelihood, and the methodology is implemented in an efficient compiled package (spBayesSurv) for broad application.

3. Article: The stochastic block model (SBM) and its variants are powerful tools for analyzing community structure in networks. An efficient network cross-validation (NCV) method is proposed to determine the optimal community structure, utilizing a degree-corrected block model (DCBM) and a block-wise node pair splitting technique. This integrated approach to community recovery minimizes the probability of node selection vanishing and has been extensively demonstrated to be effective across a wide range of community detection algorithms.

4. Article: This research models and characterizes the heterogeneity in healthcare utilization based on massive medical claims data. By translating claims into individual-level discrete event sequences, an exponential proportional hazards mixture model is employed to capture heterogeneous patient behaviors. The objective is to cluster patients according to their longitudinal utilization patterns and determine the main drivers of variation in healthcare utilization, while controlling for demographic, geographic, and health characteristics.

5. Article: This study develops a robust Bayesian mixture prior for generalized linear models (GLMs) that combines the desirable properties of the Zellner prior and truncated compound confluent hypergeometric (TCCH) prior. The new prior offers a unified approach to handle various types of data and provides a framework for model selection based on intrinsic consistency and measurement invariance. The methodology is implemented in the 'ba' package, available on CRAN, and offers a practical approach to Bayesian GLM estimation and inference.

1. Bayesian semiparametric moment estimation using exponentially tilted empirical likelihood (ETEL) offers a fully Bayesian approach that can accurately handle model misspecification. The posterior distribution derived from ETEL satisfies the Bernstein-von Mises theorem, allowing for a unified framework in comparing moment conditions. This approach allows for the discard of misspecified moments and computes the marginal likelihood using the Chib's extended Metropolis-Hastings sampler. The consistency of marginal likelihood selection is discussed, favoring the minimum moment restrictions that are valid, even under misspecification. The selection of the closer-to-true generating process is based on the Kullback-Leibler divergence, broadening the theoretical foundation of Bayesian ETEL and its practical applications.

2. In the context of spatial threshold modeling, the excursion method is employed to estimate confidence regions for temperature increases expected in North America by the mid-21st century. Asymptotic Gaussianity of the target statistic is achieved through a nested excursion approach, constructing both sub- and super-threshold excursions around the true excursion. The desired confidence level coverage probability is determined through a multiplier bootstrap, which does not require Gaussianity or stationarity assumptions. The original data's smoothness and limiting Gaussian field properties help define the temperature increase regions across North America for summer and winter seasons.

3. A comprehensive unified modeling framework is presented for arbitrarily censored spatial survival data, employing semiparametric proportional hazards and proportional odds models alongside accelerated failure time models. This approach simultaneously accommodates uncensored, interval-censored, and current status left-censored data, as well as left-truncated and time-dependent georeferenced locations. Model selection is facilitated through the use of log-pseudo marginal likelihood and deviance information criterion. The baseline survival is modeled using transformed Bernstein polynomials with a prior fit, implemented in an efficient compiled package, demonstrating broad applications in proportional odds and accelerated failure time model fitting.

4. A variant of the stochastic block model (SBM), the degree-corrected block model (DCBM), is introduced as a tool for analyzing network community structure. An efficient network cross-validation (NCV) technique is used to determine the community structure, choosing the regular SBM or the DCBM based on the NCV scores. A block-wise node pair splitting technique is combined with an integrated step for community recovery. The adjacency matrix probability selection is optimized to avoid node vanishing issues, performing well over a wide range of community recovery algorithms and validated through extensive simulations.

5. Characterizing heterogeneity in healthcare utilization patterns involves translating massive medical claims data into individual-level discrete event sequences. An exponential proportional hazards mixture model is used to capture the heterogeneous behavior of patients in their healthcare utilization. The objective is to cluster patients according to their longitudinal utilization behavior, thereby identifying the main drivers of variation in healthcare utilization while controlling for demographic, geographic, and health characteristics of the patients. This computational approach overcomes the infeasibility of fitting high-dimensional parametric proportional hazards models and offers insights into policy implications for targeted interventions in pediatric asthma care.

1. Bayesian semiparametric moment estimation within exponentially tilted empirical likelihood (ETEL) provides a fully Bayesian approach to correctly specified moments. The Bayesian ETEL posterior satisfies the Bernstein-von Mises theorem, offering a unified approach to marginal likelihood and Bayes factor for comparing moment restrictions. The method allows for the discarding of misspecified moments, with the computation of the marginal likelihood facilitated by the Chib's extended Metropolis-Hastings sampler. The selection consistency of the marginal likelihood is discussed, favoring the minimum of the maximum valid moment restrictions over misspecified marginal likelihood selection, as it selects moment restrictions closer to the true generating process, as indicated by the Kullback-Leibler divergence.

2. A comprehensive unified modeling framework for arbitrarily censored spatial survival data is introduced, utilizing semiparametric proportional hazard and proportional odds models, as well as accelerated failure time models. Unlike previous methods, this approach simultaneously accommodates uncensored, interval-censored, and current status left-censored data, handling areally and georeferenced spatial locations. Model selection is facilitated through the use of conditional Cox-Snell residuals and log pseudo marginal likelihood, ensuring an efficient and compiled package for the analysis of spatial survival data.

3. The stochastic block model (SBM) and its variants are powerful tools for analyzing network community structure, with efficient network cross-validation (NCV) determining the choice of community. The degree-corrected block model (DCBM) and block-wise node pair splitting technique are integrated into a stepwise community recovery algorithm. The selection of the adjacency matrix is based on a probability that vanishes as the node increases, demonstrating the wide applicability of community recovery algorithms across various networks.

4. Modeling and characterizing heterogeneity in healthcare utilization from massive medical claims data involves translating individual-level claims into a sequence of care utilization events. An exponential proportional hazard mixture model captures the heterogeneous behavior of patients. The objective is to cluster patients based on their longitudinal utilization patterns, identifying the main drivers of variation in healthcare utilization while controlling for demographic, geographic, and health characteristics. Computational feasibility is improved by fitting a high-dimensional proportional hazard model iteratively.

5. The development of a coherent missing data approach for nonmonotone missing data mechanisms using inverse probability weighting (IPW) has remained largely unresolved. Consequences of IPW being essentially restricted to monotone missing at random (MAR) are discussed. A novel Bayesian approach is proposed, which allows for the full likelihood to remain unrestricted, thus avoiding parametric specification of the missing data mechanism. The efficiency of IPW is improved by incorporating an incomplete augmented equation within the equation, with extensive methodology applied to evaluate key correlates of preterm delivery in HIV-infected mothers in Botswana, Africa.

1. Bayesian semi-parametric moment estimation using exponentially tilted empirical likelihood (ETEL) offers a fully Bayesian approach that can correctly account for moment misspecification. The posterior of the Bayesian ETEL satisfies the Bernstein-von Mises (BvM) theorem, providing a unified framework for computing the marginal likelihood and Bayes factors for comparing models with moment restrictions. By discarding misspecified moments, the Bayesian ETEL allows for consistent computation of the marginal likelihood using the Chib's extended Metropolis-Hastings sampler. The consistency of marginal likelihood selection is demonstrated through the minimum Kullback-Leibler divergence criterion, which selects the model closest to the true generating process. This approach has broad applications, including the estimation of temperature excursions in North America and the modeling of spatial survival data.

2. The stochastic block model (SBM) and its variants are powerful tools for analyzing community structure in networks. An efficient network cross-validation (NCV) procedure can determine the number of communities and the corresponding model. The degree-corrected block model (DCBM) integrates NCV with a block-wise node pair splitting technique to recover the community structure. This algorithm has been extensively tested and shown to be robust across a wide range of community recovery tasks. It is particularly useful for analyzing the healthcare utilization patterns of patients with persistent asthma in the Medicaid system and for understanding the main drivers of healthcare utilization variation.

3. Joint modeling of longitudinal outcomes and informative terminal events is essential in the analysis of survival data with terminal events. The inverse probability weighting (IPW) approach has been used to account for the effect of the terminal event on the response variable. A semiparametric regression model for the longitudinal outcome conditional on the right-censored terminal event time is proposed, which allows for straightforward interpretation of the treatment effect while maintaining the usual longitudinal relationships. This methodology has been applied to analyze medical costs for patients with end-stage renal disease and offers desirable asymptotic properties.

4. The mixture Zellner prior has been widely used in linear models due to its desirable properties for Bayesian selection and model averaging. An extension to the generalized linear model (GLM) using a truncated compound confluent hypergeometric (TCCH) prior assigns a mixture prior to the GLM and encompasses special cases such as the hyper-beta prime and truncated gamma priors. The TCCH prior leads to an analytical approximation of the marginal likelihood, facilitating model selection based on intrinsic criteria and prior desiderata. This methodology has been implemented in the 'ba' package, available on CRAN, and has applications in the evaluation of key correlates of preterm delivery in HIV-infected mothers in Botswana.

5. Hierarchical selection of interaction terms in high-dimensional data requires adherence to structural hierarchy constraints. Weak and strong hierarchy constraints define the existence of interactions and imply the presence of main effects. Recent computational algorithms have shown slow convergence, especially with moderate predictor dimensions. To address this, a penalized selection approach is proposed that incorporates multiple penalty terms to capture structural parsimony. This approach enjoys sharp oracle inequalities and minimax lower bounds, ensuring global optimality and computational efficiency. It has been applied to the analysis of upper extremity motor control, quantifying the reduction in movement variability during skill learning and its implications for motor learning impairments, injuries, and disease recovery.

1. Bayesian semiparametric moment estimation is a method that incorporates exponentially tilted empirical likelihood (ETEL) to achieve fully Bayesian inference even when the moments are misspecified. The Bayesian ETEL posterior distribution satisfies the Bernstein-von Mises theorem, enabling the unified computation of the marginal likelihood and Bayesian factor for model comparison. This approach allows for the selective discarding of misspecified moments while retaining valid moment restrictions. The computation of the marginal likelihood utilizes the Chib's extended Metropolis-Hastings sampler and the Jeliazkov selection consistency criterion, favoring the minimum valid moment restrictions in cases of misspecification. The selection of the closer true generating process is guided by the Kullback-Leibler divergence, broadening the theoretical foundation and practical application of Bayesian ETEL.

2. The modeling of arbitrarily censored spatial survival data is addressed through a semiparametric proportional hazard and proportional odds accelerated failure time framework. This methodology simultaneously accommodates uncensored, interval-censored, and current status left-censored data, as well as mixture and left-truncated data, allowing for the precise handling of time-dependent georeferenced locations. The formal selection and assessment of the model fit are facilitated through conditional Cox-Snell residual plots and the choice based on the log pseudo marginal likelihood (LPML) and deviance information criterion (DIC). The baseline survival is modeled using transformed Bernstein polynomials with a priori assumptions, and the analysis is conducted using an efficient, compiled package for spatial Bayesian survival analysis (spBayesSurv), which has broad applications in proportional odds and accelerated failure time modeling.

3. The stochastic block model (SBM) variant is an effective tool for analyzing network community structures, with an efficient network cross-validation (NCV) method used to determine the optimal community structure. The choice of community is guided by the regular stochastic block model and the degree-corrected block model (DCBM), employing a node pair splitting technique within an integrated stepwise community recovery process. This algorithm demonstrates solid performance across an extensive range of community recovery scenarios, establishing it as a robust choice for community detection in network analysis.

4. The characterization of heterogeneity in healthcare utilization patterns is achieved through the analysis of massive medical claims data, which translates individual-level care sequences into a discrete event framework. The utilization sequences are captured by an exponential proportional hazard mixture model, which accounts for the heterogeneous behaviors of patients. The clustering of patients according to their longitudinal utilization behaviors aims to identify the primary drivers of variation in healthcare utilization, while controlling for demographic, geographic, and health characteristics. This approach addresses the computational infeasibility of fitting parametric proportional hazard models with high-dimensional data and iteratively imputes cluster membership to draw insights from the healthcare system, as exemplified in the analysis of persistent asthma in children across multiple states.

5. The joint modeling of longitudinal outcomes with an informative terminal event, subject to right censoring, is facilitated through a marginal equation approach with inverse probability weighting. This method explicitly models the effect of the terminal event on the longitudinal responses, offering an easily interpretable contrast to treating the terminal event time as a conditional outcome. The analysis of medical costs in end-stage renal disease patients using this model leverages its desirable asymptotic properties and accounts for the complex relationship between longitudinally measured responses and the terminal event stage.

1. Semi-parametric Bayesian moment estimation within an exponentially tilted empirical likelihood framework (ETEL) allows for the accurate estimation of moments in the presence of model misspecification. The ETEL approach utilizes the Bernstein-von Mises theorem to unify the computation of marginal likelihoods and Bayesian factors, facilitating model comparison. The method effectively addresses misspecification by restricting the moments and offers computational advantages through the use of the Chib's extended Metropolis-Hastings sampler and the Jeliazkov selection consistency.

2. A unified modeling approach for spatial survival data with arbitrary censoring incorporates both semi-parametric proportional hazards and proportional odds models. This approach simultaneously accommodates uncensored, interval-censored, and current status left-censored data, offering a comprehensive framework for analyzing spatial survival data. The methodology, implemented in the SPBayesSurv package, is particularly useful in proportional odds accelerated failure time models, which often fit the data significantly better than proportional hazards models.

3. The stochastic block model (SBM) and its variants are valuable tools for analyzing community structure in networks. An efficient network cross-validation (NCV) method determines the optimal number of communities and selects the most appropriate model. The degree-corrected block model (DCBM) with NCV and a block-wise node pair splitting technique provides an integrated approach to community recovery. This methodology has been extensively validated and demonstrates robust performance across a wide range of community recovery algorithms.

4. Modeling healthcare utilization patterns from massive medical claims data involves translating claims into sequences of discrete events. This approach captures the heterogeneous behavior of patients and enables clustering individuals based on their longitudinal utilization patterns. By controlling for demographic, geographic, and health characteristics, the main drivers of healthcare utilization variation can be identified. This methodology is particularly useful for analyzing children's healthcare utilization in the Medicaid system, as demonstrated in a study on persistent asthma across six states.

5. Analyzing the joint effects of latent frailty and terminal events in the presence of right censoring requires a specialized modeling approach. A semiparametric model with inverse probability weighting offers an explicit and interpretable way to model the effect of terminal events on longitudinal outcomes. This approach maintains the usual relationships between longitudinally measured responses and time to the terminal event, providing a straightforward interpretation of the model. The methodology is numerically stable and has desirable asymptotic properties, making it suitable for analyzing medical costs in patients with end-stage renal disease.

1. "Bayesian Semiparametric Moment Casting: Incorporating Moment Misspecification into Exponentially Tilted Empirical Likelihood (ETEL) with a Fully Bayesian Approach"
2. "Bernstein von Mises Theorem and the Marginal Likelihood in Bayesian ETEL: Correctly Addressing Moment Misspecification"
3. "Marginal Likelihood and Bayesian ETEL: Posterior Satisfaction of the Bernstein von Mises Theorem for Unified Inference"
4. "Comparing Moment Restrictions in Bayesian ETEL: Discarding Misspecified Moments for Robust Estimation"
5. "Efficient Computation of Marginal Likelihood in Bayesian ETEL: The Extended Metropolis-Hastings Sampler Approach"

1. Semi-parametric Bayesian moment casting via exponentially tilted empirical likelihood (ETEL) enables accurate inference under misspecification. The Bernstein-von Mises theorem ensures the posterior distribution satisfies the Bayesian ETEL criteria, unifying the marginal likelihood computation for model comparison. A robust approach to handling misspecification is presented, where invalid moments are discarded. This method is computationally efficient, utilizing the Chib's extended Metropolis-Hastings algorithm for sampling the marginal likelihood. The consistency of the marginal likelihood selection is demonstrated, favoring the minimum of the maximum valid moment restrictions to select the model closest to the true generating process.

2. The Kullback-Leibler divergence provides a measure to expand the theoretical foundation of Bayesian ETEL and its practical applications. The goal is to construct confidence regions for threshold exceedances in spatial processes, accounting for repeated noisy measurements on a fine grid. Asymptotic Gaussianity of the target estimand is achieved through a dependent nested excursion approach, constructing sub- and super-threshold excursions. The desired confidence level coverage probability is determined, eliminating the need for a multiplier bootstrap by assuming Gaussianity and stationarity. The limiting Gaussian field determines the regions of interest, such as temperature increases in North America for the mid-21st century.

3. A comprehensive Bayesian modeling framework is proposed for arbitrarily censored spatial survival data, incorporating proportional hazards and proportional odds models, as well as accelerated failure time models. Unlike previous approaches, this methodology simultaneously accommodates uncensored, interval-censored, and current status left-censored data. A formal selection procedure is presented, facilitated by the assessment of fit using conditional Cox-Snell residuals and log-pseudo marginal likelihood. The deviance information criterion (DIC) is utilized for model comparison. The baseline survival function is modeled using Bernstein polynomials with informative priors, implemented in the efficient and compiled package 'spBayesSurv'.

4. The stochastic block model (SBM) and its variants are powerful tools for analyzing network community structure. An efficient network cross-validation (NCV) technique is introduced to determine the number of communities and the choice of the regular stochastic block model or the degree-corrected block model (DCBM). The NCV uses a block-wise node pair splitting technique, integrated with a stepwise community recovery algorithm. This approach has been extensively tested and demonstrated its effectiveness in a wide range of community recovery scenarios.

5. Modeling healthcare utilization heterogeneity from massive medical claims data involves translating claims into a sequence of discrete care events. An exponential proportional hazards mixture model captures the heterogeneous behavior of patients. The objective is to cluster patients based on their longitudinal utilization patterns, determining the main drivers of healthcare utilization while controlling for demographic, geographic, and health characteristics. Computational feasibility is addressed by an iterative procedure to impute cluster membership and draw utilization behaviors, as applied to children with persistent asthma in a Medicaid system across six states. This analysis yields policy implications for targeted interventions to improve adherence to recommended care for pediatric asthma.

